{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импорт необходимых библиотек\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from lightgbm import LGBMClassifier\n",
    "from pymystem3 import Mystem\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выгрузка данных\n",
    "data_full = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')\n",
    "data_act = data_full.sample(80000).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#проверка данных\n",
    "display(data_full.head(10))\n",
    "data_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выделение регулярных выражений\n",
    "def clear_text(data):\n",
    "    data_red = data.copy()\n",
    "    for i in range(len(data)):\n",
    "        text = re.sub(r'[^a-zA-Z]',' ', data.loc[i, 'text'])\n",
    "        text = text.split()\n",
    "        text = \" \".join(text)\n",
    "        data_red.loc[i, 'clr_text'] = text\n",
    "        if i % 10000 == 0:\n",
    "            print('Урааааа, новые 10-тысяч!', i)\n",
    "    return data_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция леммитизации\n",
    "def lemmatize(data):\n",
    "    m = WordNetLemmatizer()\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i,'lemm_text'] = ''.join(m.lemmatize(data.loc[i, 'clr_text']))\n",
    "        if i % 10000 == 0:\n",
    "            print('Урааааа, новые 10-тысяч!', i)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Урааааа, новые 10-тысяч! 0\n",
      "Урааааа, новые 10-тысяч! 10000\n",
      "Урааааа, новые 10-тысяч! 20000\n",
      "Урааааа, новые 10-тысяч! 30000\n",
      "Урааааа, новые 10-тысяч! 40000\n",
      "Урааааа, новые 10-тысяч! 50000\n",
      "Урааааа, новые 10-тысяч! 60000\n",
      "Урааааа, новые 10-тысяч! 70000\n"
     ]
    }
   ],
   "source": [
    "#чистим данные от регулярных выражений\n",
    "data_clr = clear_text(data_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Урааааа, новые 10-тысяч! 0\n",
      "Урааааа, новые 10-тысяч! 10000\n",
      "Урааааа, новые 10-тысяч! 20000\n",
      "Урааааа, новые 10-тысяч! 30000\n",
      "Урааааа, новые 10-тысяч! 40000\n",
      "Урааааа, новые 10-тысяч! 50000\n",
      "Урааааа, новые 10-тысяч! 60000\n",
      "Урааааа, новые 10-тысяч! 70000\n"
     ]
    }
   ],
   "source": [
    "#леммитизация данных\n",
    "data_lem = lemmatize(data_clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Текс без леммитизации:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"I'M NOT BLOCKED BEACAUSE I DID NOT DO ANYTHING BUT MAKE A PAGE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Текс после леммитизации:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I M NOT BLOCKED BEACAUSE I DID NOT DO ANYTHING BUT MAKE A PAGE'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('Текс без леммитизации:', data_act['text'][0])\n",
    "display('Текс после леммитизации:',data_lem['lemm_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_lem.drop('toxic', axis = 1)\n",
    "target = data_lem['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#делим данные на тестовую и обучающую выборку\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы обучающих данных: (60000, 96138)\n",
      "Размер матрицы тестовых данных: (20000, 96138)\n"
     ]
    }
   ],
   "source": [
    "#находим TF-IDF для данных\n",
    "corpus_train = features_train['lemm_text'].values.astype('U')\n",
    "corpus_test = features_test['lemm_text'].values.astype('U')\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf_train = count_tf_idf.fit_transform(corpus_train) \n",
    "tf_idf_test = count_tf_idf.transform(corpus_test) \n",
    "print(\"Размер матрицы обучающих данных:\", tf_idf_train.shape)\n",
    "print(\"Размер матрицы тестовых данных:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#определение гипепараметров для модели \"случайный лес\"\n",
    "#model_for = RandomForestClassifier()\n",
    "\n",
    "#parametrs = {'max_depth': range(1,6), 'n_estimators': range(1, 21, 10)}\n",
    "#grid_search = GridSearchCV(model_for, parametrs, scoring = f1)\n",
    "#grid_search.fit(tf_idf_train, target_train)\n",
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определение гипепараметров для модели \"дерево решений\"\n",
    "#model_tree = DecisionTreeClassifier()\n",
    "\n",
    "#parametrs = {'max_depth': range(1,6), 'min_samples_split': range(2, 6, 2)}\n",
    "#grid_search = GridSearchCV(model_tree, parametrs, scoring = f1)\n",
    "#grid_search.fit(tf_idf_train, target_train)\n",
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определение гипепараметров для модели \"логистичская регерссия\"\n",
    "#model_log = LogisticRegression()\n",
    "\n",
    "#parametrs = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "#grid_search = GridSearchCV(model_log, parametrs, scoring = f1)\n",
    "#grid_search.fit(tf_idf_train, target_train)\n",
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определение гипепараметров для модели \"LGB\"\n",
    "#model_lgb = LGBMClassifier(boosting_type ='gbdt')\n",
    "\n",
    "#parametrs = {'max_depth': range(1,3), 'num_leaves': range(31, 93, 31)}\n",
    "#grid_search = GridSearchCV(model_lgb, parametrs, scoring = f1)\n",
    "#grid_search.fit(tf_idf_train, target_train)\n",
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы. Шаг 1\n",
    "1) Для удобства и быстроты обучения модели, беру не весь набор данных, а только 80к записей.    \n",
    "2) Проведена леммитизация предложений и проведен анализ регулярных выражений.   \n",
    "3) Найдены гиперпараметры для каждой модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1 для случайного леса (валидационные данные) 0.02\n"
     ]
    }
   ],
   "source": [
    "#обучение модели \"Случайный лес\"\n",
    "model_for = RandomForestClassifier(max_depth=5, n_estimators=1)\n",
    "\n",
    "#предсказание модели \"Случайный лес\"\n",
    "model_for.fit(tf_idf_train, target_train)\n",
    "predict_for = model_for.predict(tf_idf_test)\n",
    "print('Значение F1 для случайного леса (валидационные данные)', \"%.2f\" % f1_score(predict_for, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1 для случайного леса (валидационные данные) 0.52\n"
     ]
    }
   ],
   "source": [
    "#обучение модели \"Дерево решений\"\n",
    "model_tree = DecisionTreeClassifier(max_depth=5, min_samples_split=4)\n",
    "\n",
    "#предсказание модели \"Дерево решений\"\n",
    "model_tree.fit(tf_idf_train, target_train)\n",
    "predict_tree = model_tree.predict(tf_idf_test)\n",
    "print('Значение F1 для случайного леса (валидационные данные)', \"%.2f\" % f1_score(predict_tree, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1 для логистической регрессии (валидационные данные) 0.77\n"
     ]
    }
   ],
   "source": [
    "#обучение модели \"Логистическая регрессия\"\n",
    "model_log = LogisticRegression(C=100)\n",
    "\n",
    "#предсказания модели \"Логистическая регрессия\"\n",
    "model_log.fit(tf_idf_train, target_train)\n",
    "predict_log = model_log.predict(tf_idf_test)\n",
    "print('Значение F1 для логистической регрессии (валидационные данные)', \"%.2f\" % f1_score(predict_log, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1 для LGB (валидационные данные) 0.54\n"
     ]
    }
   ],
   "source": [
    "#обучение модели \"LGB\"\n",
    "model_lgb = LGBMClassifier(boosting_type ='gbdt', max_depth=2, num_leaves=31)\n",
    "\n",
    "#предсказания модели \"LGB\"\n",
    "model_lgb.fit(tf_idf_train, target_train)\n",
    "predict_lgb = model_lgb.predict(tf_idf_test)\n",
    "print('Значение F1 для LGB (валидационные данные)', \"%.2f\" % f1_score(predict_lgb, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Результаты RMSE на валидационных данных</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>0.015686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Дерево решений</td>\n",
       "      <td>0.520086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.767423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LGB</td>\n",
       "      <td>0.541503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Результаты RMSE на валидационных данных\n",
       "Случайный лес                                           0.015686\n",
       "Дерево решений                                          0.520086\n",
       "Логистическая регрессия                                 0.767423\n",
       "LGB                                                     0.541503"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#таблица с общими результатами\n",
    "ml = ['Случайный лес', 'Дерево решений', 'Логистическая регрессия', 'LGB']\n",
    "data = {\n",
    "  'Результаты RMSE на валидационных данных':  [f1_score(predict_for, target_test), f1_score(predict_tree, target_test), f1_score(predict_log, target_test), f1_score(predict_lgb, target_test)]\n",
    "}\n",
    "data_ml = pd.DataFrame(data=data, index=ml)\n",
    "display(data_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всех лучше себя показала модель ML - логистическая регрессия! На половине данных результат F1 получился 0,76!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
